[2024-10-16T07:17:15.765+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2024-10-16T07:17:15.773+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_scraping_dag.run_booking_scrapy manual__2024-10-16T07:17:15.036463+00:00 [queued]>
[2024-10-16T07:17:15.776+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_scraping_dag.run_booking_scrapy manual__2024-10-16T07:17:15.036463+00:00 [queued]>
[2024-10-16T07:17:15.777+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2024-10-16T07:17:15.783+0000] {taskinstance.py:2888} INFO - Executing <Task(BashOperator): run_booking_scrapy> on 2024-10-16 07:17:15.036463+00:00
[2024-10-16T07:17:15.787+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'booking_scraping_dag', 'run_booking_scrapy', 'manual__2024-10-16T07:17:15.036463+00:00', '--job-id', '57', '--raw', '--subdir', 'DAGS_FOLDER/booking_dag.py', '--cfg-path', '/tmp/tmpn8gvhq1h']
[2024-10-16T07:17:15.789+0000] {standard_task_runner.py:105} INFO - Job 57: Subtask run_booking_scrapy
[2024-10-16T07:17:15.789+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=461) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-10-16T07:17:15.790+0000] {standard_task_runner.py:72} INFO - Started process 462 to run task
[2024-10-16T07:17:15.812+0000] {task_command.py:467} INFO - Running <TaskInstance: booking_scraping_dag.run_booking_scrapy manual__2024-10-16T07:17:15.036463+00:00 [running]> on host a2fb8bdf9c2b
[2024-10-16T07:17:15.846+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='21120576@student.hcmus.edu.vn' AIRFLOW_CTX_DAG_OWNER='cheep' AIRFLOW_CTX_DAG_ID='booking_scraping_dag' AIRFLOW_CTX_TASK_ID='run_booking_scrapy' AIRFLOW_CTX_EXECUTION_DATE='2024-10-16T07:17:15.036463+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-10-16T07:17:15.036463+00:00'
[2024-10-16T07:17:15.846+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-10-16T07:17:15.846+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-10-16T07:17:15.847+0000] {logging_mixin.py:190} INFO - Current task name:run_booking_scrapy state:running start_date:2024-10-16 07:17:15.773544+00:00
[2024-10-16T07:17:15.847+0000] {logging_mixin.py:190} INFO - Dag name:booking_scraping_dag and current dag run status:running
[2024-10-16T07:17:15.847+0000] {taskinstance.py:731} INFO - ::endgroup::
[2024-10-16T07:17:15.847+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2024-10-16T07:17:15.848+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'cd /opt/***/booking && scrapy crawl booking']
[2024-10-16T07:17:15.852+0000] {subprocess.py:86} INFO - Output:
[2024-10-16T07:17:16.630+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: booking)
[2024-10-16T07:17:16.631+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.7.0, Python 3.12.6 (main, Sep 12 2024, 22:40:30) [GCC 12.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.2.2 4 Jun 2024), cryptography 42.0.8, Platform Linux-6.10.4-linuxkit-aarch64-with-glibc2.36
[2024-10-16T07:17:16.633+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.addons] INFO: Enabled addons:
[2024-10-16T07:17:16.633+0000] {subprocess.py:93} INFO - []
[2024-10-16T07:17:16.633+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [asyncio] DEBUG: Using selector: EpollSelector
[2024-10-16T07:17:16.633+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
[2024-10-16T07:17:16.633+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
[2024-10-16T07:17:16.641+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.extensions.telnet] INFO: Telnet Password: f489d2005f7ecc54
[2024-10-16T07:17:16.749+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.middleware] INFO: Enabled extensions:
[2024-10-16T07:17:16.749+0000] {subprocess.py:93} INFO - ['scrapy.extensions.corestats.CoreStats',
[2024-10-16T07:17:16.749+0000] {subprocess.py:93} INFO -  'scrapy.extensions.telnet.TelnetConsole',
[2024-10-16T07:17:16.749+0000] {subprocess.py:93} INFO -  'scrapy.extensions.memusage.MemoryUsage',
[2024-10-16T07:17:16.749+0000] {subprocess.py:93} INFO -  'scrapy.extensions.logstats.LogStats']
[2024-10-16T07:17:16.749+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.crawler] INFO: Overridden settings:
[2024-10-16T07:17:16.750+0000] {subprocess.py:93} INFO - {'BOT_NAME': 'booking',
[2024-10-16T07:17:16.750+0000] {subprocess.py:93} INFO -  'FEED_EXPORT_ENCODING': 'utf-8',
[2024-10-16T07:17:16.750+0000] {subprocess.py:93} INFO -  'NEWSPIDER_MODULE': 'booking.spiders',
[2024-10-16T07:17:16.750+0000] {subprocess.py:93} INFO -  'REDIRECT_ENABLED': False,
[2024-10-16T07:17:16.750+0000] {subprocess.py:93} INFO -  'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
[2024-10-16T07:17:16.750+0000] {subprocess.py:93} INFO -  'ROBOTSTXT_OBEY': True,
[2024-10-16T07:17:16.750+0000] {subprocess.py:93} INFO -  'SPIDER_MODULES': ['booking.spiders'],
[2024-10-16T07:17:16.750+0000] {subprocess.py:93} INFO -  'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
[2024-10-16T07:17:16.750+0000] {subprocess.py:93} INFO -  'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
[2024-10-16T07:17:16.751+0000] {subprocess.py:93} INFO -                '(KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'}
[2024-10-16T07:17:16.809+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
[2024-10-16T07:17:16.809+0000] {subprocess.py:93} INFO - ['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
[2024-10-16T07:17:16.810+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
[2024-10-16T07:17:16.810+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
[2024-10-16T07:17:16.810+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
[2024-10-16T07:17:16.810+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
[2024-10-16T07:17:16.810+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
[2024-10-16T07:17:16.810+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.retry.RetryMiddleware',
[2024-10-16T07:17:16.810+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
[2024-10-16T07:17:16.810+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
[2024-10-16T07:17:16.810+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
[2024-10-16T07:17:16.811+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
[2024-10-16T07:17:16.811+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.stats.DownloaderStats']
[2024-10-16T07:17:16.811+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.middleware] INFO: Enabled spider middlewares:
[2024-10-16T07:17:16.811+0000] {subprocess.py:93} INFO - ['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
[2024-10-16T07:17:16.811+0000] {subprocess.py:93} INFO -  'scrapy.spidermiddlewares.referer.RefererMiddleware',
[2024-10-16T07:17:16.811+0000] {subprocess.py:93} INFO -  'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
[2024-10-16T07:17:16.811+0000] {subprocess.py:93} INFO -  'scrapy.spidermiddlewares.depth.DepthMiddleware']
[2024-10-16T07:17:16.811+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.middleware] INFO: Enabled item pipelines:
[2024-10-16T07:17:16.811+0000] {subprocess.py:93} INFO - []
[2024-10-16T07:17:16.811+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.core.engine] INFO: Spider opened
[2024-10-16T07:17:16.813+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
[2024-10-16T07:17:16.813+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[2024-10-16T07:17:16.814+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:16.814 | DEBUG    | booking.spiders:start_requests:37 - Constructed URL: https://www.booking.com/searchresults.en-gb.html?ss=Viet+Nam&checkin_year=2024&checkin_month=10&checkin_monthday=11&checkout_year=2024&checkout_month=10&checkout_monthday=12&no_rooms=1
[2024-10-16T07:17:17.123+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:17 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): publicsuffix.org:443
[2024-10-16T07:17:17.331+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:17 [urllib3.connectionpool] DEBUG: https://publicsuffix.org:443 "GET /list/public_suffix_list.dat HTTP/11" 200 86540
[2024-10-16T07:17:17.503+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.booking.com/robots.txt> (referer: None)
[2024-10-16T07:17:18.608+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.booking.com/searchresults.en-gb.html?ss=Viet+Nam&checkin_year=2024&checkin_month=10&checkin_monthday=11&checkout_year=2024&checkout_month=10&checkout_monthday=12&no_rooms=1> (referer: None)
[2024-10-16T07:17:18.754+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.booking.com/searchresults.en-gb.html?ss=Viet+Nam&checkin_year=2024&checkin_month=10&checkin_monthday=11&checkout_year=2024&checkout_month=10&checkout_monthday=12&no_rooms=1> (referer: None)
[2024-10-16T07:17:18.754+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2024-10-16T07:17:18.754+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/scrapy/utils/defer.py", line 279, in iter_errback
[2024-10-16T07:17:18.754+0000] {subprocess.py:93} INFO -     yield next(it)
[2024-10-16T07:17:18.754+0000] {subprocess.py:93} INFO -           ^^^^^^^^
[2024-10-16T07:17:18.755+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/scrapy/utils/python.py", line 350, in __next__
[2024-10-16T07:17:18.755+0000] {subprocess.py:93} INFO -     return next(self.data)
[2024-10-16T07:17:18.755+0000] {subprocess.py:93} INFO -            ^^^^^^^^^^^^^^^
[2024-10-16T07:17:18.755+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/scrapy/utils/python.py", line 350, in __next__
[2024-10-16T07:17:18.755+0000] {subprocess.py:93} INFO -     return next(self.data)
[2024-10-16T07:17:18.755+0000] {subprocess.py:93} INFO -            ^^^^^^^^^^^^^^^
[2024-10-16T07:17:18.756+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
[2024-10-16T07:17:18.756+0000] {subprocess.py:93} INFO -     for r in iterable:
[2024-10-16T07:17:18.756+0000] {subprocess.py:93} INFO -              ^^^^^^^^
[2024-10-16T07:17:18.756+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 352, in <genexpr>
[2024-10-16T07:17:18.756+0000] {subprocess.py:93} INFO -     return (self._set_referer(r, response) for r in result or ())
[2024-10-16T07:17:18.756+0000] {subprocess.py:93} INFO -                                                     ^^^^^^^^^^^^
[2024-10-16T07:17:18.756+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
[2024-10-16T07:17:18.756+0000] {subprocess.py:93} INFO -     for r in iterable:
[2024-10-16T07:17:18.756+0000] {subprocess.py:93} INFO -              ^^^^^^^^
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 27, in <genexpr>
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -     return (r for r in result or () if self._filter(r, spider))
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -                        ^^^^^^^^^^^^
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -     for r in iterable:
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -              ^^^^^^^^
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 31, in <genexpr>
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -     return (r for r in result or () if self._filter(r, response, spider))
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -                        ^^^^^^^^^^^^
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -     for r in iterable:
[2024-10-16T07:17:18.757+0000] {subprocess.py:93} INFO -              ^^^^^^^^
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO -   File "/opt/***/booking/booking/spiders/__init__.py", line 41, in parse_first_page
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO -     body = self.retrieve_graphql_body(response)
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO -   File "/opt/***/booking/booking/spiders/__init__.py", line 83, in retrieve_graphql_body
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO -     with open("../search_query.graphql", "r") as file:
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO -          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO - FileNotFoundError: [Errno 2] No such file or directory: '../search_query.graphql'
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:18 [scrapy.core.engine] INFO: Closing spider (finished)
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO - {'downloader/request_bytes': 1224,
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO -  'downloader/request_count': 2,
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO -  'downloader/request_method_count/GET': 2,
[2024-10-16T07:17:18.758+0000] {subprocess.py:93} INFO -  'downloader/response_bytes': 247519,
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'downloader/response_count': 2,
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'downloader/response_status_count/200': 2,
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'elapsed_time_seconds': 1.942339,
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'finish_reason': 'finished',
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'finish_time': datetime.datetime(2024, 10, 16, 7, 17, 18, 755622, tzinfo=datetime.timezone.utc),
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'httpcompression/response_bytes': 1399648,
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'httpcompression/response_count': 2,
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'log_count/DEBUG': 7,
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'log_count/ERROR': 1,
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'log_count/INFO': 10,
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'memusage/max': 219029504,
[2024-10-16T07:17:18.759+0000] {subprocess.py:93} INFO -  'memusage/startup': 219029504,
[2024-10-16T07:17:18.760+0000] {subprocess.py:93} INFO -  'response_received_count': 2,
[2024-10-16T07:17:18.760+0000] {subprocess.py:93} INFO -  'robotstxt/request_count': 1,
[2024-10-16T07:17:18.760+0000] {subprocess.py:93} INFO -  'robotstxt/response_count': 1,
[2024-10-16T07:17:18.760+0000] {subprocess.py:93} INFO -  'robotstxt/response_status_count/200': 1,
[2024-10-16T07:17:18.760+0000] {subprocess.py:93} INFO -  'scheduler/dequeued': 1,
[2024-10-16T07:17:18.760+0000] {subprocess.py:93} INFO -  'scheduler/dequeued/memory': 1,
[2024-10-16T07:17:18.760+0000] {subprocess.py:93} INFO -  'scheduler/enqueued': 1,
[2024-10-16T07:17:18.760+0000] {subprocess.py:93} INFO -  'scheduler/enqueued/memory': 1,
[2024-10-16T07:17:18.760+0000] {subprocess.py:93} INFO -  'spider_exceptions/FileNotFoundError': 1,
[2024-10-16T07:17:18.760+0000] {subprocess.py:93} INFO -  'start_time': datetime.datetime(2024, 10, 16, 7, 17, 16, 813283, tzinfo=datetime.timezone.utc)}
[2024-10-16T07:17:18.760+0000] {subprocess.py:93} INFO - 2024-10-16 07:17:18 [scrapy.core.engine] INFO: Spider closed (finished)
[2024-10-16T07:17:18.843+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2024-10-16T07:17:18.853+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-10-16T07:17:18.854+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=booking_scraping_dag, task_id=run_booking_scrapy, run_id=manual__2024-10-16T07:17:15.036463+00:00, execution_date=20241016T071715, start_date=20241016T071715, end_date=20241016T071718
[2024-10-16T07:17:18.857+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2024-10-16T07:17:18.857+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-10-16T07:17:18.858+0000] {logging_mixin.py:190} INFO - Dag name:booking_scraping_dag queued_at:2024-10-16 07:17:15.046280+00:00
[2024-10-16T07:17:18.858+0000] {logging_mixin.py:190} INFO - Task hostname:a2fb8bdf9c2b operator:BashOperator
[2024-10-16T07:17:18.892+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2024-10-16T07:17:18.900+0000] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-10-16T07:17:18.901+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
